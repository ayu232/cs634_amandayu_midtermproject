{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928f5d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf8504",
   "metadata": {},
   "source": [
    "## Project Part 1: Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9b6370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactional datasets created in 'Documents/transactional_datasets'\n"
     ]
    }
   ],
   "source": [
    "# load retailer data from CSV\n",
    "data_path = \"/Users/amanda/Documents/transactional_datasets/retailers.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# group items \n",
    "retailers = df.groupby(\"Retailer\")[\"Item\"].apply(list).to_dict()\n",
    "\n",
    "# define output directory\n",
    "output_dir = \"/Users/amanda/Documents/transactional_datasets/transactions\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to create deterministic transactions\n",
    "def generate_transactions(items, n=20):\n",
    "    transactions = []\n",
    "    for i in range(n):\n",
    "        start = i % len(items)\n",
    "        end = (start + (i % 5 + 3)) % len(items)\n",
    "        if start < end:\n",
    "            trans_items = items[start:end]\n",
    "        else:\n",
    "            trans_items = items[start:] + items[:end]\n",
    "        transactions.append(trans_items)\n",
    "    return transactions\n",
    "\n",
    "# Build datasets and save\n",
    "for retailer, items in retailers.items():\n",
    "    transactions = generate_transactions(items)\n",
    "    df_out = pd.DataFrame({\n",
    "        \"TransactionID\": [f\"{i+1}\" for i in range(len(transactions))],\n",
    "        \"ItemsPurchased\": [\", \".join(t) for t in transactions]\n",
    "    })\n",
    "    df_out.to_csv(f\"{output_dir}/{retailer}.csv\", index=False)\n",
    "\n",
    "print(\"Transactional datasets created in 'Documents/transactional_datasets'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00b7ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec6351",
   "metadata": {},
   "source": [
    "## Project Part 2: Brute Force Algorithm - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1bd319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Amazon ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Costco ===\n",
      "\n",
      "=== Processing Walmart ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Nike ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing BestBuy ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Across All Retailers ===\n",
      "Retailer  Apriori Itemsets  Apriori Rules  FP-Growth Itemsets  FP-Growth Rules  Brute Force Time (s)  Apriori Time (s)  FP-Growth Time (s)\n",
      "  Amazon               310           3092                 310             3092                 0.135             2.828               0.077\n",
      "  Costco               310           3092                 310             3092                 0.027             0.037               0.043\n",
      " Walmart               310           3092                 310             3092                 0.021             0.142               0.110\n",
      "    Nike               310           3092                 310             3092                 0.046             0.030               0.387\n",
      " BestBuy               310           3092                 310             3092                 0.025             0.152               0.055\n",
      "\n",
      "=== Average Execution Time (All Retailers) ===\n",
      "  Algorithm  Execution Time (s)\n",
      "Brute Force               0.051\n",
      "    Apriori               0.638\n",
      "  FP-Growth               0.134\n",
      "\n",
      "All results saved in: /Users/amanda/Documents/transactional_datasets/results\n"
     ]
    }
   ],
   "source": [
    "#  Helper functions\n",
    "\n",
    "def get_support(itemset, transactions):\n",
    "    count = sum(1 for t in transactions if itemset.issubset(t))\n",
    "    return count / len(transactions)\n",
    "\n",
    "# brute force frequent itemset generation\n",
    "def get_frequent_itemsets(transactions, min_support=0.3):\n",
    "    all_items = sorted(set(itertools.chain.from_iterable(transactions)))\n",
    "    frequent_itemsets = []\n",
    "    k = 1\n",
    "\n",
    "    while True:\n",
    "        candidates = list(itertools.combinations(all_items, k))\n",
    "        current_frequents = []\n",
    "\n",
    "        for candidate in candidates:\n",
    "            itemset = set(candidate)\n",
    "            support = get_support(itemset, transactions)\n",
    "            if support >= min_support:\n",
    "                current_frequents.append((itemset, support))\n",
    "\n",
    "        if not current_frequents:\n",
    "            break\n",
    "\n",
    "        frequent_itemsets.extend(current_frequents)\n",
    "        k += 1\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "# generate association rules from frequent itemsets\n",
    "def generate_association_rules(frequent_itemsets, transactions, min_confidence=0.6):\n",
    "    rules = []\n",
    "    for itemset, support in frequent_itemsets:\n",
    "        if len(itemset) < 2:\n",
    "            continue\n",
    "        for i in range(1, len(itemset)):\n",
    "            for antecedent in itertools.combinations(itemset, i):\n",
    "                antecedent = set(antecedent)\n",
    "                consequent = itemset - antecedent\n",
    "                if not consequent:\n",
    "                    continue\n",
    "                support_antecedent = get_support(antecedent, transactions)\n",
    "                confidence = support / support_antecedent if support_antecedent > 0 else 0\n",
    "                if confidence >= min_confidence:\n",
    "                    rules.append({\n",
    "                        \"Antecedent\": \", \".join(sorted(antecedent)),\n",
    "                        \"Consequent\": \", \".join(sorted(consequent)),\n",
    "                        \"Support\": round(support, 3),\n",
    "                        \"Confidence\": round(confidence, 3)\n",
    "                    })\n",
    "    return rules\n",
    "\n",
    "\n",
    "#  Paths \n",
    "input_dir = \"/Users/amanda/Documents/transactional_datasets/transactions\"\n",
    "output_dir = \"/Users/amanda/Documents/transactional_datasets/results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#  Parameter combinations to test \n",
    "parameter_sets = [\n",
    "    {\"support\": 0.3, \"confidence\": 0.6},\n",
    "    {\"support\": 0.2, \"confidence\": 0.5},\n",
    "    {\"support\": 0.1, \"confidence\": 0.4}\n",
    "]\n",
    "\n",
    "summary = []\n",
    "\n",
    "# process all retailer CSVs \n",
    "for filename in os.listdir(input_dir):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    retailer = os.path.splitext(filename)[0]\n",
    "    filepath = os.path.join(input_dir, filename)\n",
    "    print(f\"\\n=== Processing {retailer} ===\")\n",
    "\n",
    "    # Load transactions\n",
    "    df = pd.read_csv(filepath)\n",
    "    transactions = [set(t.split(\", \")) for t in df[\"ItemsPurchased\"]]\n",
    "    df_onehot = transactions_to_df(transactions)\n",
    "\n",
    "    #  Brute Force Timing \n",
    "    start_bf = time.time()\n",
    "    frequent_itemsets = get_frequent_itemsets(transactions, min_support=min_support)\n",
    "    rules = generate_association_rules(frequent_itemsets, transactions, min_confidence=min_confidence)\n",
    "    end_bf = time.time()\n",
    "    brute_force_time = round(end_bf - start_bf, 3)\n",
    "\n",
    "    #  Apriori Timing \n",
    "    start_ap = time.time()\n",
    "    apriori_itemsets = apriori(df_onehot, min_support=min_support, use_colnames=True)\n",
    "    apriori_rules = association_rules(apriori_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    end_ap = time.time()\n",
    "    apriori_time = round(end_ap - start_ap, 3)\n",
    "\n",
    "    #  FP-Growth Timing \n",
    "    start_fp = time.time()\n",
    "    fpg_itemsets = fpgrowth(df_onehot, min_support=min_support, use_colnames=True)\n",
    "    fpg_rules = association_rules(fpg_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    end_fp = time.time()\n",
    "    fpg_time = round(end_fp - start_fp, 3)\n",
    "\n",
    "    #  Save results \n",
    "    # Apriori\n",
    "    apriori_itemsets[\"Itemset\"] = apriori_itemsets[\"itemsets\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    apriori_itemsets = apriori_itemsets[[\"Itemset\", \"support\"]]\n",
    "    apriori_itemsets.to_csv(f\"{output_dir}/{retailer}_apriori_itemsets.csv\", index=False)\n",
    "\n",
    "    apriori_rules[\"antecedents\"] = apriori_rules[\"antecedents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    apriori_rules[\"consequents\"] = apriori_rules[\"consequents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    apriori_rules = apriori_rules[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]]\n",
    "    apriori_rules.to_csv(f\"{output_dir}/{retailer}_apriori_rules.csv\", index=False)\n",
    "\n",
    "    # FP-Growth\n",
    "    fpg_itemsets[\"Itemset\"] = fpg_itemsets[\"itemsets\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    fpg_itemsets = fpg_itemsets[[\"Itemset\", \"support\"]]\n",
    "    fpg_itemsets.to_csv(f\"{output_dir}/{retailer}_fpgrowth_itemsets.csv\", index=False)\n",
    "\n",
    "    fpg_rules[\"antecedents\"] = fpg_rules[\"antecedents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    fpg_rules[\"consequents\"] = fpg_rules[\"consequents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    fpg_rules = fpg_rules[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]]\n",
    "    fpg_rules.to_csv(f\"{output_dir}/{retailer}_fpgrowth_rules.csv\", index=False)\n",
    "\n",
    "    #  Add to summary\n",
    "    summary.append({\n",
    "        \"Retailer\": retailer,\n",
    "        \"Apriori Itemsets\": len(apriori_itemsets),\n",
    "        \"Apriori Rules\": len(apriori_rules),\n",
    "        \"FP-Growth Itemsets\": len(fpg_itemsets),\n",
    "        \"FP-Growth Rules\": len(fpg_rules),\n",
    "        \"Brute Force Time (s)\": brute_force_time,\n",
    "        \"Apriori Time (s)\": apriori_time,\n",
    "        \"FP-Growth Time (s)\": fpg_time\n",
    "    })\n",
    "\n",
    "#  Summary Table \n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"\\n=== Summary Across All Retailers ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "summary_df.to_csv(f\"{output_dir}/summary.csv\", index=False)\n",
    "\n",
    "# --- Average Execution Time Across All Retailers ---\n",
    "avg_times = {\n",
    "    \"Algorithm\": [\"Brute Force\", \"Apriori\", \"FP-Growth\"],\n",
    "    \"Execution Time (s)\": [\n",
    "        round(summary_df[\"Brute Force Time (s)\"].mean(), 3),\n",
    "        round(summary_df[\"Apriori Time (s)\"].mean(), 3),\n",
    "        round(summary_df[\"FP-Growth Time (s)\"].mean(), 3)\n",
    "    ]\n",
    "}\n",
    "avg_times_df = pd.DataFrame(avg_times)\n",
    "\n",
    "print(\"\\n=== Average Execution Time (All Retailers) ===\")\n",
    "print(avg_times_df.to_string(index=False))\n",
    "avg_times_df.to_csv(f\"{output_dir}/execution_times.csv\", index=False)\n",
    "\n",
    "print(f\"\\nAll results saved in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06541ed6",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Amazon ===\n",
      "\n",
      "=== Processing Costco ===\n",
      "\n",
      "=== Processing Walmart ===\n",
      "\n",
      "=== Processing Nike ===\n",
      "\n",
      "=== Processing BestBuy ===\n",
      "\n",
      "=== Summary Across All Retailers ===\n",
      "Retailer  Total Frequent Itemsets  Total Rules\n",
      "  Amazon                       40          100\n",
      "  Costco                       40          100\n",
      " Walmart                       40          100\n",
      "    Nike                       40          100\n",
      " BestBuy                       40          100\n",
      "\n",
      "All results saved in: /Users/amanda/Documents/transactional_datasets/results\n"
     ]
    }
   ],
   "source": [
    "# User-specified thresholds\n",
    "min_support = float(input(\"Enter minimum support (e.g., 0.3): \") or 0.3)\n",
    "min_confidence = float(input(\"Enter minimum confidence (e.g., 0.6): \") or 0.6)\n",
    "\n",
    "# === Helper Functions ===\n",
    "\n",
    "def get_support(itemset, transactions):\n",
    "    count = sum(1 for t in transactions if itemset.issubset(t))\n",
    "    return count / len(transactions)\n",
    "\n",
    "def get_frequent_itemsets(transactions, min_support):\n",
    "    all_items = sorted(set(itertools.chain.from_iterable(transactions)))\n",
    "    frequent_itemsets = []\n",
    "    k = 1\n",
    "\n",
    "    while True:\n",
    "        candidates = list(itertools.combinations(all_items, k))\n",
    "        current_frequents = []\n",
    "\n",
    "        for candidate in candidates:\n",
    "            itemset = set(candidate)\n",
    "            support = get_support(itemset, transactions)\n",
    "            if support >= min_support:\n",
    "                current_frequents.append((itemset, support))\n",
    "\n",
    "        if not current_frequents:\n",
    "            break\n",
    "\n",
    "        frequent_itemsets.extend(current_frequents)\n",
    "        k += 1\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "def generate_association_rules(frequent_itemsets, transactions, min_confidence):\n",
    "    rules = []\n",
    "    for itemset, support in frequent_itemsets:\n",
    "        if len(itemset) < 2:\n",
    "            continue  # rules require at least 2 items\n",
    "        for i in range(1, len(itemset)):\n",
    "            for antecedent in itertools.combinations(itemset, i):\n",
    "                antecedent = set(antecedent)\n",
    "                consequent = itemset - antecedent\n",
    "                if not consequent:\n",
    "                    continue\n",
    "                support_antecedent = get_support(antecedent, transactions)\n",
    "                confidence = support / support_antecedent if support_antecedent > 0 else 0\n",
    "                if confidence >= min_confidence:\n",
    "                    rules.append({\n",
    "                        \"Antecedent\": \", \".join(sorted(antecedent)),\n",
    "                        \"Consequent\": \", \".join(sorted(consequent)),\n",
    "                        \"Support\": round(support, 3),\n",
    "                        \"Confidence\": round(confidence, 3)\n",
    "                    })\n",
    "    return rules\n",
    "\n",
    "# === Process All 5 Retailer Databases ===\n",
    "summary = []\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    retailer = os.path.splitext(filename)[0]\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "    print(f\"\\n=== Processing {retailer} ===\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    transactions = [set(t.split(\", \")) for t in df[\"ItemsPurchased\"]]\n",
    "\n",
    "    # Step 1: Find frequent itemsets\n",
    "    frequent_itemsets = get_frequent_itemsets(transactions, min_support)\n",
    "\n",
    "    # Save frequent itemsets\n",
    "    freq_data = [\n",
    "        {\"Itemset\": \", \".join(sorted(itemset)), \"Support\": round(support, 3)}\n",
    "        for itemset, support in frequent_itemsets\n",
    "    ]\n",
    "    freq_df = pd.DataFrame(freq_data)\n",
    "    freq_df.to_csv(f\"{output_dir}/{retailer}_frequent_itemsets.csv\", index=False)\n",
    "\n",
    "    # Step 2: Generate association rules\n",
    "    rules = generate_association_rules(frequent_itemsets, transactions, min_confidence)\n",
    "\n",
    "    # Save association rules\n",
    "    rules_df = pd.DataFrame(rules)\n",
    "    rules_df.to_csv(f\"{output_dir}/{retailer}_association_rules.csv\", index=False)\n",
    "\n",
    "    summary.append({\n",
    "        \"Retailer\": retailer,\n",
    "        \"Total Frequent Itemsets\": len(frequent_itemsets),\n",
    "        \"Total Rules\": len(rules)\n",
    "    })\n",
    "\n",
    "# === Summary ===\n",
    "print(\"\\n=== Summary Across All Retailers ===\")\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(summary_df.to_string(index=False))\n",
    "summary_df.to_csv(f\"{output_dir}/summary.csv\", index=False)\n",
    "\n",
    "print(f\"\\nAll results saved in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69874852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (2.3.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (3.5.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.2->mlxtend) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/amanda/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab42719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e2a7f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Amazon ===\n",
      "\n",
      "=== Processing Costco ===\n",
      "\n",
      "=== Processing Walmart ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Nike ===\n",
      "\n",
      "=== Processing BestBuy ===\n",
      "\n",
      "=== Summary Across All Retailers ===\n",
      "Retailer  Apriori Itemsets  Apriori Rules  FP-Growth Itemsets  FP-Growth Rules\n",
      "  Amazon                40            100                  40              100\n",
      "  Costco                40            100                  40              100\n",
      " Walmart                40            100                  40              100\n",
      "    Nike                40            100                  40              100\n",
      " BestBuy                40            100                  40              100\n",
      "\n",
      "All results saved in: /Users/amanda/Documents/transactional_datasets/results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#  Helper function: Convert transactions to one-hot encoded DataFrame \n",
    "def transactions_to_df(transactions):\n",
    "    all_items = sorted(set(item for t in transactions for item in t))\n",
    "    one_hot = pd.DataFrame(0, index=range(len(transactions)), columns=all_items)\n",
    "    for i, t in enumerate(transactions):\n",
    "        one_hot.loc[i, list(t)] = 1\n",
    "    return one_hot\n",
    "\n",
    "summary = []\n",
    "\n",
    "# process all retailer CSVs \n",
    "for filename in os.listdir(input_dir):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    retailer = os.path.splitext(filename)[0]\n",
    "    filepath = os.path.join(input_dir, filename)\n",
    "    print(f\"\\n=== Processing {retailer} ===\")\n",
    "\n",
    "    # Load transactions\n",
    "    df = pd.read_csv(filepath)\n",
    "    transactions = [set(t.split(\", \")) for t in df[\"ItemsPurchased\"]]\n",
    "    df_onehot = transactions_to_df(transactions)\n",
    "\n",
    "    #  Apriori \n",
    "    apriori_itemsets = apriori(df_onehot, min_support=min_support, use_colnames=True)\n",
    "    apriori_itemsets[\"Itemset\"] = apriori_itemsets[\"itemsets\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    apriori_itemsets = apriori_itemsets[[\"Itemset\", \"support\"]]\n",
    "    apriori_itemsets.to_csv(f\"{output_dir}/{retailer}_apriori_itemsets.csv\", index=False)\n",
    "\n",
    "    apriori_rules = association_rules(\n",
    "        apriori(df_onehot, min_support=min_support, use_colnames=True),\n",
    "        metric=\"confidence\",\n",
    "        min_threshold=min_confidence\n",
    "    )\n",
    "    apriori_rules[\"antecedents\"] = apriori_rules[\"antecedents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    apriori_rules[\"consequents\"] = apriori_rules[\"consequents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    apriori_rules = apriori_rules[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]]\n",
    "    apriori_rules.to_csv(f\"{output_dir}/{retailer}_apriori_rules.csv\", index=False)\n",
    "\n",
    "    #  FP-Growth \n",
    "    fpg_itemsets = fpgrowth(df_onehot, min_support=min_support, use_colnames=True)\n",
    "    fpg_itemsets[\"Itemset\"] = fpg_itemsets[\"itemsets\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    fpg_itemsets = fpg_itemsets[[\"Itemset\", \"support\"]]\n",
    "    fpg_itemsets.to_csv(f\"{output_dir}/{retailer}_fpgrowth_itemsets.csv\", index=False)\n",
    "\n",
    "    fpg_rules = association_rules(\n",
    "        fpgrowth(df_onehot, min_support=min_support, use_colnames=True),\n",
    "        metric=\"confidence\",\n",
    "        min_threshold=min_confidence\n",
    "    )\n",
    "    fpg_rules[\"antecedents\"] = fpg_rules[\"antecedents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    fpg_rules[\"consequents\"] = fpg_rules[\"consequents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    fpg_rules = fpg_rules[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]]\n",
    "    fpg_rules.to_csv(f\"{output_dir}/{retailer}_fpgrowth_rules.csv\", index=False)\n",
    "\n",
    "    summary.append({\n",
    "        \"Retailer\": retailer,\n",
    "        \"Apriori Itemsets\": len(apriori_itemsets),\n",
    "        \"Apriori Rules\": len(apriori_rules),\n",
    "        \"FP-Growth Itemsets\": len(fpg_itemsets),\n",
    "        \"FP-Growth Rules\": len(fpg_rules)\n",
    "    })\n",
    "\n",
    "# summary\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"\\n=== Summary Across All Retailers ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "summary_df.to_csv(f\"{output_dir}/summary.csv\", index=False)\n",
    "\n",
    "print(f\"\\nAll results saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e14ff2",
   "metadata": {},
   "source": [
    "## Part 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5de7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Available Retailer Datasets ===\n",
      "1. Amazon.csv\n",
      "2. Costco.csv\n",
      "3. Walmart.csv\n",
      "4. Nike.csv\n",
      "5. BestBuy.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Execution Summary ===\n",
      "Selected Dataset: Amazon.csv\n",
      "Minimum Support: 0.2\n",
      "Minimum Confidence: 0.6\n",
      "\n",
      "Execution complete. User-specified results saved in:\n",
      "/Users/amanda/Documents/transactional_datasets/results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/amanda/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#  Paths \n",
    "input_dir = \"/Users/amanda/Documents/transactional_datasets/transactions\"\n",
    "output_dir = \"/Users/amanda/Documents/transactional_datasets/results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# part 4: Execution & Input Parameters \n",
    "import sys\n",
    "\n",
    "# Available datasets dynamically from the transactions folder\n",
    "available_datasets = [\n",
    "    f for f in os.listdir(input_dir) if f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "if not available_datasets:\n",
    "    print(\"No datasets found in the transactions directory. Please run the data creation part first.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\n=== Available Retailer Datasets ===\")\n",
    "for i, dataset in enumerate(available_datasets, start=1):\n",
    "    print(f\"{i}. {dataset}\")\n",
    "\n",
    "#  dataset selection\n",
    "while True:\n",
    "    try:\n",
    "        choice = int(input(\"\\nSelect a dataset by number: \"))\n",
    "        if 1 <= choice <= len(available_datasets):\n",
    "            selected_dataset = available_datasets[choice - 1]\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Please enter a number between 1 and {len(available_datasets)}.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "#  minimum support\n",
    "while True:\n",
    "    try:\n",
    "        min_support = float(input(\"Enter minimum support (e.g., 0.3): \"))\n",
    "        if 0 < min_support <= 1:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Support must be between 0 and 1.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a numeric value between 0 and 1.\")\n",
    "\n",
    "#  minimum confidence\n",
    "while True:\n",
    "    try:\n",
    "        min_confidence = float(input(\"Enter minimum confidence (e.g., 0.6): \"))\n",
    "        if 0 < min_confidence <= 1:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Confidence must be between 0 and 1.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a numeric value between 0 and 1.\")\n",
    "\n",
    "# confirm input\n",
    "print(\"\\n=== Execution Summary ===\")\n",
    "print(f\"Selected Dataset: {selected_dataset}\")\n",
    "print(f\"Minimum Support: {min_support}\")\n",
    "print(f\"Minimum Confidence: {min_confidence}\")\n",
    "\n",
    "# Load and process the selected dataset\n",
    "selected_path = os.path.join(input_dir, selected_dataset)\n",
    "df = pd.read_csv(selected_path)\n",
    "transactions = [set(t.split(\", \")) for t in df[\"ItemsPurchased\"]]\n",
    "\n",
    "# Run Apriori and FP-Growth using user-specified parameters\n",
    "df_onehot = transactions_to_df(transactions)\n",
    "\n",
    "# apriori\n",
    "apriori_itemsets = apriori(df_onehot, min_support=min_support, use_colnames=True)\n",
    "apriori_rules = association_rules(apriori_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "# FP-Growth\n",
    "fpg_itemsets = fpgrowth(df_onehot, min_support=min_support, use_colnames=True)\n",
    "fpg_rules = association_rules(fpg_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "# Save \n",
    "apriori_itemsets.to_csv(f\"{output_dir}/{selected_dataset.replace('.csv', '')}_user_apriori_itemsets.csv\", index=False)\n",
    "apriori_rules.to_csv(f\"{output_dir}/{selected_dataset.replace('.csv', '')}_user_apriori_rules.csv\", index=False)\n",
    "fpg_itemsets.to_csv(f\"{output_dir}/{selected_dataset.replace('.csv', '')}_user_fpgrowth_itemsets.csv\", index=False)\n",
    "fpg_rules.to_csv(f\"{output_dir}/{selected_dataset.replace('.csv', '')}_user_fpgrowth_rules.csv\", index=False)\n",
    "\n",
    "print(\"\\nExecution complete. User-specified results saved in:\")\n",
    "print(output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
